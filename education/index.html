<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Grover Lab</title>
  <meta name="description" content="Grover Lab<br> Department of Bioengineering<br> University of California, Riverside<br> Riverside, CA 92521
">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://groverlab.org/education/">
  <link rel="alternate" type="application/rss+xml" title="Grover Lab" href="http://groverlab.org/feed.xml">

  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-34084184-1', 'auto');
  ga('send', 'pageview');

</script>


</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Grover Lab</a> 


    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
          <a class="page-link" href="/">Home</a>
          <a class="page-link" href="/research">Research</a>
          <a class="page-link" href="/education">Education</a>
          <a class="page-link" href="/hnbfpr">HNBFPR</a>
          <a class="page-link" href="/people">People</a>
          <a class="page-link" href="/contact">Contact</a>
      </div>
    </nav>


  </div>

  <div class="wrapper">

  <p style="font-size:15px">Department of Bioengineering, University of California, Riverside</p>

  </div>
  

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="home">

  <h1>Education</h1>


  <ul class="post-list">
    
      <li>
      <br>
           
        <h1>           <a class="post-link" href="/education/2016-06-29-printsafe.html">The PrintSafe Project</a></h1>
        <p><a href="http://printsafe.org">The PrintSafe Project</a></p>

<p>We are on the threshold of an explosion in the popularity of 3D printers.  As the original patents on 3D printing expire, the market is being flooded with low-cost 3D printers, and the number of inexpensive 3D printers sold per year is doubling every year.  As 3D printers grow less expensive, they are becoming increasingly popular in libraries, schools, and homes; even toy 3D printers for children are now available.</p>

<p>However, the popularity of 3D printers has blinded us to their potential risks.  The undeniable “coolness” of 3D printing distracts us from the reality that 3D printers are like tiny factories; the materials they use and waste they generate can be hazardous to our health and the environment.  But unlike factories, 3D printers are largely unregulated and are being welcomed into our schools and homes.</p>

<p>After we published our findings on the <a href="http://groverlab.org/research/2015-01-01-3d-tox.html">toxicity of 3D-printed parts</a>, we were surprised at the number of emails and phone calls we received from 3D printer users with questions about the safety of their printers.  These questions ranged from elementary school students who were concerned about the printer in their classroom, to the head of occupational health and safety at a major university who wanted to develop a set of “best practices” for 3D printer users on her campus but was unable to find official guidance on 3D printer safety from printer manufacturers or regulatory groups.</p>

<p>As a result, most 3D printer users are completely unaware of the health and environmental risks of their printers and have no clear place to go to learn about these risks.  A quick browse through <a href="http://thingiverse.com">thingiverse.com</a> (a website where 3D printer users share their creations) returns scores of 3D-printed coffee mugs, kitchen tools, and other objects that expose users to potentially hazardous substances.  And online message boards are filled with questions from printer users, questions like “what is the smell that comes from my printer?” (probably ABS plastic fumes, which can cause headaches and respiratory irritation and should be ventilated outside your school) and “how do I dispose of the solvent I use to clean up parts after printing at my house?” (responses ranged from “flush it down the toilet” to “throw it on a bonfire!”)</p>

<p>To better inform 3D printer users and policymakers, we are creating <a href="http://printsafe.org">The PrintSafe Project</a>, a one-stop clearinghouse for up-to-date information about the hazards of 3D printing.  The centerpiece of the project will be a website, <a href="http://printsafe.org">http://printsafe.org</a>.</p>

<ul>
  <li>
    <p>For users who already own a 3D printer, <a href="http://printsafe.org">http://printsafe.org</a> will provide information about health and environmental hazards specific to the user’s specific type of printer and advice on how to reduce these hazards.</p>
  </li>
  <li>
    <p>For users who are considering purchasing a 3D printer, <a href="http://printsafe.org">http://printsafe.org</a> will guide the user in selecting the least-hazardous type of printer for their specific needs.</p>
  </li>
  <li>
    <p>Policymakers at the local and state level can use <a href="http://printsafe.org">http://printsafe.org</a> as a resource when drafting guidelines about safe use of 3D printers in our businesses, schools, and homes.</p>
  </li>
</ul>

<p><a href="http://printsafe.org">The PrintSafe project is still under development, but you are welcome to browse through the beta version of our site.</a> Please contact project lead <a href="&#109;&#097;&#105;&#108;&#116;&#111;:&#119;&#103;&#114;&#111;&#118;&#101;&#114;&#064;&#101;&#110;&#103;&#114;&#046;&#117;&#099;&#114;&#046;&#101;&#100;&#117;">William Grover</a> for more information.</p>


      </li>
    
      <li>
      <br>
           
        <h1>           <a class="post-link" href="/education/2015-07-01-anechoic.html">Anechoic</a></h1>
        <p><a href="https://itunes.apple.com/us/app/anechoic/id1014061397">Available for iPhone on the Apple App Store</a></p>

<p><img src="/assets/ngss-3d.png" width="30%" align="left" style="PADDING-RIGHT: 20px" />We are big proponents of the <a href="http://www.nextgenscience.org">Next Generation Science Standards</a> (NGSS).  We’re especially interested the NGSS <i>Practices dimension</i>, which seeks to integrate problem-solving engineering experiences in K-12 science classes.  While engineering practices can be included in physics classes relatively easily, creating engineering practices for chemistry and biology classes can be more challenging for teachers.  We’re trying to help by <b>creating technologies that support bioengineering and chemical engineering practices in K-12 schools.</b></p>

<p>Anechoic plays a user-selected sound from your phone’s speaker, then uses your phone’s microphone to measure how much of the sound is reflected back to the phone. When your phone is passed in front of an object, the  sound bouncing off of the object can be detected by Anechoic, and in some cases the rough shape of the object can be discerned in the signal plotted on the app (similar to medical ultrasound).</p>

<p>Students can use Anechoic to explore how sound waves interact with matter, answering questions like:</p>

<ul>
  <li>How does the distance between the phone and the object affect the intensity of reflected sound?</li>
  <li>How does the frequency of the sound determine how much of the sound is absorbed or reflected by an object?</li>
  <li>How do an object’s shape and material properties influence how sound is absorbed or reflected by the object?</li>
  <li>How can sound be used to detect objects or measure the distance to an object?</li>
</ul>

<h2 id="anechoic-and-the-next-generation-science-standards">Anechoic and the Next Generation Science Standards</h2>

<p>One of the “Three Dimensions” of the Next Generation Science Standards is “Practices,” which mandates that teachers provide K-12 students with experience in engineering solutions to problems.  Providing students with engineering practices in the biosciences can be especially challenging, in part because of the specialized and expensive equipment often used in bioscience. For example, a teacher may wish to provide her students with an ultrasound practice (to understand biomedical imaging) but be unable to obtain the expensive and specialized equipment required to actually perform ultrasound in the classroom.  Anechoic is intended to help fill this gap by offering students hands-on experiences with the principles of biotechniques like ultrasound, using only a smartphone and no additional equipment.</p>

<h2 id="using-anechoic">Using Anechoic</h2>

<ol>
  <li>
    <p>Scroll through the list of playable sounds and select one.  The list includes simple tones (with constant frequencies ranging from 100 Hz to 20,000 Hz), white and pink noise (which contain multiple frequencies simultaneously), linear and logarithmic sweeps (which ramp the frequency from low to high) and a burst (which emits short “pings” similar to sonar).</p>
  </li>
  <li>
    <p>Orient your phone for your experiment.  You’ll want to aim the bottom edge of the phone (the side where the cable connector is) at whatever object you’re studying.  For example, if you’re trying to visualize an object by scanning across it and measuring the sound it reflects (like ultrasound), place your phone to the left of the object with the bottom edge aiming to the left of the object.</p>
  </li>
  <li>
    <p>Tap Start, and Anechoic will simultaneously play the selected sound and record the reflected sound.  If you don’t hear anything, use the volume buttons on your phone to turn up the volume.  Also note that some of the frequencies are too low or too high to be heard by humans!</p>
  </li>
  <li>
    <p>Perform your experiment.  For example, if you’re scanning across an object in an ultrasound-like experiment, slowly pass the phone from left to right across the object.  You’ve got up to 30 seconds to complete your experiment.</p>
  </li>
  <li>
    <p>When you are finished with your experiment, tap Stop.  Anechoic will stop playing and recording.</p>
  </li>
  <li>
    <p>Tap Plot to view a plot of the intensity of the reflected sound vs. time.  A scanned object may appear as a peak or dip in this plot (depending on whether the object reflects or absorbs the played sound).  You can save a picture of this plot by simultaneously pressing the Home and Power buttons on your phone (this saves a screenshot to your Photos collection).  When you are done with your plot, tap the screen to go back.</p>
  </li>
  <li>
    <p>If you want to explore the reflected sound further, tap the Email button.  A blank email will be created that includes the reflected sound file as an attachment.  More details on how to analyze and visualize this sound file are available below.</p>
  </li>
</ol>

<h2 id="analyzing-and-visualizing-the-reflected-sound-file">Analyzing and visualizing the reflected sound file</h2>

<p>Anechoic saves a file that contains the reflected sound; you can use the Email button in Anechoic to send this file to yourself.  This file is an ordinary sound file, and you can play it on your computer using standard programs that play sound files, like Quicktime on a Mac or Windows Media Player on a PC.</p>

<p>If you want to visualize the reflected sound file (to create a plot like the one shown on the Anechoic app) you need some specialized software.  Here’s one way to do it:</p>

<p>Mac users:</p>

<ol>
  <li>
    <p>Install the free decompression tool The Unarchiver by following the instructions here:  http://unarchiver.c3.cx/unarchiver</p>
  </li>
  <li>
    <p>Install the free multimedia codec FFMPEG by downloading, uncompressing, and installing this file:  http://evermeet.cx/ffmpeg/ffmpeg-2.7.2.7z</p>
  </li>
  <li>
    <p>Install the free version of Anaconda by following the instructions here:  http://continuum.io/downloads</p>
  </li>
  <li>
    <p>Download and unzip my sample Python analysis code from here:  https://github.com/groverlab/anechoic-python/archive/master.zip</p>
  </li>
  <li>
    <p>Run the sample Python program called “anechoic.py” which should open the sample audio file called “Anechoic_reflected_sound_file.m4a” and plot the file.</p>
  </li>
  <li>
    <p>If everything works, you can replace that sample audio file with your own audio file (emailed from the Anechoic app) and rerun the Python program “anechoic.py” to plot it.</p>
  </li>
</ol>

<p>PC users:</p>

<ol>
  <li>
    <p>Install the free decompression tool 7-Zip by following the instructions here:  http://7-zip.org</p>
  </li>
  <li>
    <p>Install the free multimedia codec FFMPEG by downloading, uncompressing, and installing this file:  http://ffmpeg.zeranoe.com/builds/win32/static/ffmpeg-20150722-git-a176bbc-win32-static.7z</p>
  </li>
  <li>
    <p>Install the free version of Anaconda by following the instructions here:  http://continuum.io/downloads</p>
  </li>
  <li>
    <p>Download and unzip my sample Python analysis code from here:  https://github.com/groverlab/anechoic-python/archive/master.zip</p>
  </li>
  <li>
    <p>Run the sample Python program called “anechoic.py” which should open the sample audio file called “Anechoic_reflected_sound_file.m4a” and plot the file.
6
. If everything works, you can replace that sample audio file with your own audio file (emailed from the Anechoic app) and rerun the Python program “anechoic.py” to plot it.</p>
  </li>
</ol>

<h2 id="help">Help</h2>

<p>If you’re having problems with Anechoic, contact William Grover at wgrover@engr.ucr.edu.</p>

<h2 id="acknowledgements">Acknowledgements</h2>

<p>The development of Anechoic was supported in part by the National Science Foundation’s Instrument Development for Biological Research Program under award DBI-1353974.</p>

      </li>
    
  </ul>

  <p class="rss-subscribe">subscribe <a href="/feed.xml">via RSS</a></p>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Grover Lab</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>Grover Lab</li>
          <li><a href="mailto:wgrover@engr.ucr.edu">wgrover@engr.ucr.edu</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/groverlab"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">groverlab</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/wgrover"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">wgrover</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Grover Lab<br> Department of Bioengineering<br> University of California, Riverside<br> Riverside, CA 92521
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
